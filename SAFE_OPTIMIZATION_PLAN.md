# Safe Performance Optimization Plan

## üõ°Ô∏è Safety Strategy

Since the current code is **functionally working**, we'll use a **safe, incremental approach** with Git branches and testing at each step.

---

## üìã Step-by-Step Safe Implementation Plan

### **Phase 0: Preparation (5 minutes)**

1. **Create a feature branch** (keeps main safe)
   ```bash
   git checkout -b performance-optimization
   ```

2. **Verify current state**
   ```bash
   git log --oneline -5  # Check recent commits
   git status            # Ensure clean working directory
   ```

3. **Tag current working version** (easy rollback point)
   ```bash
   git tag v-working-before-optimization
   git push origin v-working-before-optimization
   ```

---

### **Phase 1: Quick Wins (Low Risk, High Impact)**

**Estimated Time:** 1-2 hours  
**Risk Level:** ‚ö†Ô∏è Low  
**Expected Improvement:** -2 to -3 seconds

#### Changes:
1. Reduce `top_k` values in RAG retrieval
2. Reduce LLM timeout from 8s to 5s
3. Shorten prompts (remove redundant text)

#### Safety Steps:
1. **Commit after each small change:**
   ```bash
   # Change 1: Reduce top_k
   git add agent_app/graphs/astrology_agent_graph.py
   git commit -m "perf: Reduce RAG top_k from 5 to 3 (general), 3 to 2 (house-specific)"
   
   # Change 2: Reduce timeout
   git add agent_app/rag/supabase_rag.py
   git commit -m "perf: Reduce LLM timeout from 8s to 5s"
   
   # Change 3: Shorten prompts
   git add agent_app/rag/supabase_rag.py
   git commit -m "perf: Shorten LLM prompts by removing redundant instructions"
   ```

2. **Test after each commit:**
   - Test with a simple query: "What's my 7th house like?"
   - Verify response quality is maintained
   - Check response time improvement

3. **If something breaks:**
   ```bash
   git reset --hard HEAD~1  # Undo last commit
   # Or revert to tag:
   git reset --hard v-working-before-optimization
   ```

---

### **Phase 2: Chart Data Caching (Medium Risk, High Impact)**

**Estimated Time:** 1-2 hours  
**Risk Level:** ‚ö†Ô∏è Medium  
**Expected Improvement:** -5 to -8 seconds (for follow-up queries)

#### Changes:
1. Add caching logic to `conversation_manager.py`
2. Cache BAV/SAV, Dasha, Gochara data per session
3. Invalidate cache if birth data changes

#### Safety Steps:
1. **Create a separate commit for caching:**
   ```bash
   git add agent_app/conversation/manager.py
   git commit -m "perf: Add chart data caching per session"
   ```

2. **Test thoroughly:**
   - First query: Should calculate (no cache)
   - Second query: Should use cache (faster)
   - Change birth data: Should recalculate
   - Verify data accuracy matches non-cached version

3. **Add feature flag** (optional, for easy rollback):
   ```python
   # In conversation_manager.py
   ENABLE_CHART_CACHE = os.getenv("ENABLE_CHART_CACHE", "true").lower() == "true"
   
   if ENABLE_CHART_CACHE:
       cached_data = get_cached_chart_data(session_id)
   ```

---

### **Phase 3: Parallel API Calls (Higher Risk, Highest Impact)**

**Estimated Time:** 2-3 hours  
**Risk Level:** ‚ö†Ô∏è‚ö†Ô∏è Medium-High  
**Expected Improvement:** -5 to -7 seconds

#### Changes:
1. Convert `calculate_chart_data()` to async
2. Use `asyncio.gather()` for parallel API calls
3. Ensure FastAPI endpoints are async-compatible

#### Safety Steps:
1. **Create a backup branch first:**
   ```bash
   git checkout -b performance-optimization-parallel
   git branch performance-optimization-backup  # Backup branch
   ```

2. **Make changes incrementally:**
   ```bash
   # Step 1: Add async helper functions (test first)
   git commit -m "perf: Add async API call helpers"
   
   # Step 2: Convert calculate_chart_data to async
   git commit -m "perf: Make API calls parallel using asyncio"
   ```

3. **Test extensively:**
   - Test with all 3 APIs (BAV/SAV, Dasha, Gochara)
   - Test with only 1 API needed
   - Test error handling (one API fails)
   - Verify data accuracy matches sequential version

4. **If issues occur:**
   ```bash
   git checkout performance-optimization-backup
   # Or revert specific commit:
   git revert HEAD
   ```

---

### **Phase 4: Advanced RAG (Low Risk, Medium Impact)**

**Estimated Time:** 1-2 hours  
**Risk Level:** ‚ö†Ô∏è Low  
**Expected Improvement:** -0.5 to -1 second

#### Changes:
1. Switch to `retrieve_context_advanced()` with RPC
2. Batch retrieval for multiple houses

#### Safety Steps:
1. **Verify RPC function exists in Supabase first:**
   - Check if `match_vedic_knowledge` function exists
   - Test RPC function manually

2. **Add fallback logic:**
   ```python
   try:
       chunks = rag_system.retrieve_context_advanced(...)
   except Exception as e:
       # Fallback to basic retrieval
       chunks = rag_system.retrieve_context(...)
   ```

3. **Commit with fallback:**
   ```bash
   git commit -m "perf: Use advanced RAG with fallback to basic retrieval"
   ```

---

## üîÑ Git Workflow for Safe Changes

### **Recommended Branch Structure:**
```
main (production)
  ‚îî‚îÄ‚îÄ performance-optimization (feature branch)
       ‚îú‚îÄ‚îÄ performance-optimization-phase1 (quick wins)
       ‚îú‚îÄ‚îÄ performance-optimization-phase2 (caching)
       ‚îú‚îÄ‚îÄ performance-optimization-phase3 (parallel)
       ‚îî‚îÄ‚îÄ performance-optimization-phase4 (advanced RAG)
```

### **Daily Workflow:**
```bash
# Start of day
git checkout performance-optimization
git pull origin main  # Get latest changes

# Make changes
# ... edit files ...

# Test locally
# ... run tests ...

# Commit small changes
git add .
git commit -m "perf: [description]"

# Push to remote (backup)
git push origin performance-optimization

# End of day: Merge to main if stable
git checkout main
git merge performance-optimization
git push origin main
```

---

## ‚úÖ Testing Checklist (After Each Phase)

### **Functional Tests:**
- [ ] Simple query: "What's my 7th house like?"
- [ ] Dasha query: "Tell me about my current dasa"
- [ ] Gochara query: "What are my current transits?"
- [ ] Complex query: "Analyze my 7th and 10th houses"
- [ ] Verify response quality (not degraded)
- [ ] Verify response accuracy (data matches)

### **Performance Tests:**
- [ ] Measure response time (before/after)
- [ ] Test with cached data (follow-up queries)
- [ ] Test with fresh data (first query)
- [ ] Test error scenarios (API failures)

### **Edge Cases:**
- [ ] Missing birth data
- [ ] Invalid birth data
- [ ] API timeout scenarios
- [ ] Network errors
- [ ] Concurrent requests

---

## üö® Rollback Plan

### **If Something Breaks:**

1. **Quick Rollback (Last Commit):**
   ```bash
   git reset --hard HEAD~1
   ```

2. **Rollback to Tag (Working Version):**
   ```bash
   git reset --hard v-working-before-optimization
   ```

3. **Rollback to Main Branch:**
   ```bash
   git checkout main
   git branch -D performance-optimization  # Delete broken branch
   ```

4. **Revert Specific Commit:**
   ```bash
   git revert <commit-hash>
   ```

---

## üìä Monitoring During Optimization

### **Metrics to Track:**
1. **Response Time:**
   - First query (no cache)
   - Follow-up query (with cache)
   - Average response time

2. **Error Rate:**
   - API call failures
   - LLM timeouts
   - RAG retrieval errors

3. **Resource Usage:**
   - Memory usage (caching increases this)
   - CPU usage (parallel calls)
   - API rate limits

### **Logging:**
Add timing logs to track improvements:
```python
import time

start_time = time.time()
# ... operation ...
duration = time.time() - start_time
print(f"‚è±Ô∏è Operation took {duration:.2f}s")
```

---

## üéØ Recommended Order of Implementation

1. ‚úÖ **Phase 1: Quick Wins** (Start here - safest)
2. ‚úÖ **Phase 2: Chart Data Caching** (High impact, medium risk)
3. ‚úÖ **Phase 4: Advanced RAG** (Low risk, can do in parallel)
4. ‚úÖ **Phase 3: Parallel API Calls** (Do last - highest risk, highest impact)

---

## üí° Pro Tips

1. **One change at a time:** Don't combine multiple optimizations in one commit
2. **Test after each commit:** Catch issues early
3. **Keep commits small:** Easier to revert if needed
4. **Use feature flags:** Easy to disable optimizations if needed
5. **Document changes:** Add comments explaining why changes were made
6. **Monitor in production:** Deploy to staging first, then production

---

## üìù Next Steps

1. **Create feature branch:**
   ```bash
   git checkout -b performance-optimization
   git tag v-working-before-optimization
   ```

2. **Start with Phase 1 (Quick Wins):**
   - Reduce `top_k` values
   - Reduce LLM timeout
   - Shorten prompts

3. **Test and commit:**
   - Test each change
   - Commit if working
   - Push to remote

4. **Iterate through phases:**
   - Complete Phase 1 ‚Üí Test ‚Üí Commit
   - Move to Phase 2 ‚Üí Test ‚Üí Commit
   - Continue...

5. **Merge to main when stable:**
   ```bash
   git checkout main
   git merge performance-optimization
   git push origin main
   ```

---

## ‚úÖ Summary

- ‚úÖ **Code is already committed** ‚Üí Safe to create branches
- ‚úÖ **Use feature branches** ‚Üí Keeps main branch safe
- ‚úÖ **Tag working version** ‚Üí Easy rollback point
- ‚úÖ **Incremental changes** ‚Üí Test after each step
- ‚úÖ **Small commits** ‚Üí Easy to revert if needed
- ‚úÖ **Test thoroughly** ‚Üí Verify functionality maintained

**You're safe to proceed!** üöÄ
